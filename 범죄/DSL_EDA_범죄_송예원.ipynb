{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6c3758",
   "metadata": {},
   "source": [
    "## [1] 유튜브 영상 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8540f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (4.16.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: idna in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver-manager in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (4.0.1)\n",
      "Requirement already satisfied: packaging in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (23.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: requests in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da65e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%shell` not found.\n"
     ]
    }
   ],
   "source": [
    "%%shell\n",
    "sudo apt -y update\n",
    "sudo apt install -y wget curl unzip\n",
    "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
    "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
    "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "dpkg -i google-chrome-stable_current_amd64.deb\n",
    "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
    "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
    "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
    "chmod +x /tmp/chromedriver\n",
    "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
    "\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c657041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromedriver-autoinstaller in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (0.6.3)\r\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (from chromedriver-autoinstaller) (23.2)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages/chromedriver_autoinstaller/120/chromedriver'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install chromedriver-autoinstaller\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b85d7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b367925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec8b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /Users/yewonsong/opt/anaconda3/lib/python3.9/site-packages (15.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb186fc",
   "metadata": {},
   "source": [
    "### MBC 2015~2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a03145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cdd8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll():\n",
    "    try:        \n",
    "        # 페이지 내 스크롤 높이 받아오기\n",
    "        last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        while True:\n",
    "            # 임의의 페이지 로딩 시간 설정\n",
    "            # PC환경에 따라 로딩시간 최적화를 통해 scraping 시간 단축 가능\n",
    "            pause_time = random.uniform(1, 2)\n",
    "            # 페이지 최하단까지 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "            # 페이지 로딩 대기\n",
    "            time.sleep(pause_time)\n",
    "            # 무한 스크롤 동작을 위해 살짝 위로 스크롤(i.e., 페이지를 위로 올렸다가 내리는 제스쳐)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight-50)\")\n",
    "            time.sleep(pause_time)\n",
    "            # 페이지 내 스크롤 높이 새롭게 받아오기\n",
    "            new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            # 스크롤을 완료한 경우(더이상 페이지 높이 변화가 없는 경우)\n",
    "            if new_page_height == last_page_height:\n",
    "                print(\"스크롤 완료\")\n",
    "                break\n",
    "                \n",
    "            # 스크롤 완료하지 않은 경우, 최하단까지 스크롤\n",
    "            else:\n",
    "                last_page_height = new_page_height\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"에러 발생: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d26874ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n"
     ]
    }
   ],
   "source": [
    "#예시 after:2016-12-31 before:2018-1-1 음주운전\n",
    "yr_interest = [2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "for interest in yr_interest:\n",
    "    bf = interest-1\n",
    "    aft = interest+1\n",
    "    \n",
    "    yt_url = f'https://www.youtube.com/@MBCNEWS11/search?query=after%3A{bf}-12-31%20before%3A{aft}-1-1%20%EC%9D%8C%EC%A3%BC%EC%9A%B4%EC%A0%84'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(yt_url)\n",
    "    \n",
    "    # 브라우저 로드가 완료되기 위한 시간\n",
    "    time.sleep(2)\n",
    "    body = driver.find_element(By.TAG_NAME, value='body')\n",
    "\n",
    "    scroll()\n",
    "\n",
    "    # selenium을 이용해서 HTML문서를 변환한 후에는 반드시 브라우저를 종료\n",
    "    html = bs(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "\n",
    "    titleList = []\n",
    "    contentUrlList = []\n",
    "    viewcountList = []\n",
    "    commentcountList = []\n",
    "\n",
    "    for content in html.select('a#video-title'):\n",
    "        #제목 수집\n",
    "        title = content.get('title')\n",
    "\n",
    "        #URL 수집\n",
    "        content_url = 'https://www.youtube.com'+content.get('href')\n",
    "\n",
    "        #조회수 수집\n",
    "        label = content.get('aria-label')\n",
    "        split_label = label.split()\n",
    "        idx = label.split().index('조회수')\n",
    "        viewcount = split_label[idx+1]\n",
    "        viewcount=viewcount.replace(\",\",\"\")\n",
    "        viewcount=viewcount.replace(\"회\",\"\")\n",
    "\n",
    "        #빈 리스트에 추가\n",
    "        titleList.append(title)\n",
    "        contentUrlList.append(content_url)\n",
    "        viewcountList.append(int(viewcount))\n",
    "\n",
    "    yt_dic = {'영상제목' : titleList,'영상주소' : contentUrlList,'조회수' : viewcountList}\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    yt_df = pd.DataFrame(yt_dic)\n",
    "\n",
    "    #날짜 가져오기\n",
    "    dateList = []\n",
    "    for link in yt_df['영상주소']:\n",
    "        yt = YouTube(link)\n",
    "        dateList.append(yt.publish_date.date())\n",
    "\n",
    "    yt_df['날짜'] = dateList\n",
    "\n",
    "    #엑셀 파일로 저장\n",
    "    yt_df.to_excel(f'MBC_{interest}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163ddbd",
   "metadata": {},
   "source": [
    "### YTN 2015~2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5200d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 60] Operation timed out>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1347\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    946\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    831\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gq/gkzpyqzs4813v8b0n439g5bc0000gn/T/ipykernel_69474/1037428562.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myt_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'영상주소'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mdateList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0myt_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'날짜'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdateList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mpublish_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_date\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mwatch_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytube/request.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, extra_headers, timeout)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextra_headers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytube/request.py\u001b[0m in \u001b[0;36m_execute_request\u001b[0;34m(url, method, headers, data, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid URL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# nosec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    535\u001b[0m                                   '_open', req)\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1390\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 60] Operation timed out>"
     ]
    }
   ],
   "source": [
    "yr_interest = [2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "for interest in yr_interest:\n",
    "    bf = interest-1\n",
    "    aft = interest+1\n",
    "    \n",
    "    yt_url = f'https://www.youtube.com/@ytnnews24/search?query=after%3A{bf}-12-31%20before%3A{aft}-1-1%20%EC%9D%8C%EC%A3%BC%EC%9A%B4%EC%A0%84'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(yt_url)\n",
    "    \n",
    "    # 브라우저 로드가 완료되기 위한 시간\n",
    "    time.sleep(2)\n",
    "    body = driver.find_element(By.TAG_NAME, value='body')\n",
    "\n",
    "    scroll()\n",
    "\n",
    "    # selenium을 이용해서 HTML문서를 변환한 후에는 반드시 브라우저를 종료\n",
    "    html = bs(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "\n",
    "    titleList = []\n",
    "    contentUrlList = []\n",
    "    viewcountList = []\n",
    "    commentcountList = []\n",
    "\n",
    "    for content in html.select('a#video-title'):\n",
    "        #제목 수집\n",
    "        title = content.get('title')\n",
    "\n",
    "        #URL 수집\n",
    "        content_url = 'https://www.youtube.com'+content.get('href')\n",
    "\n",
    "        #조회수 수집\n",
    "        label = content.get('aria-label')\n",
    "        split_label = label.split()\n",
    "        idx = label.split().index('조회수')\n",
    "        viewcount = split_label[idx+1]\n",
    "        viewcount=viewcount.replace(\",\",\"\")\n",
    "        viewcount=viewcount.replace(\"회\",\"\")\n",
    "\n",
    "        #빈 리스트에 추가\n",
    "        titleList.append(title)\n",
    "        contentUrlList.append(content_url)\n",
    "        viewcountList.append(int(viewcount))\n",
    "\n",
    "    yt_dic = {'영상제목' : titleList,'영상주소' : contentUrlList,'조회수' : viewcountList}\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    yt_df = pd.DataFrame(yt_dic)\n",
    "\n",
    "    #날짜 가져오기\n",
    "    dateList = []\n",
    "    for link in yt_df['영상주소']:\n",
    "        yt = YouTube(link)\n",
    "        dateList.append(yt.publish_date.date())\n",
    "\n",
    "    yt_df['날짜'] = dateList\n",
    "\n",
    "    #엑셀 파일로 저장\n",
    "    yt_df.to_excel(f'YTN_{interest}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678ea88",
   "metadata": {},
   "source": [
    "### SBS 2015~2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7efb6fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n"
     ]
    }
   ],
   "source": [
    "yr_interest = [2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "for interest in yr_interest:\n",
    "    bf = interest-1\n",
    "    aft = interest+1\n",
    "    \n",
    "    yt_url = f'https://www.youtube.com/@sbsnews8/search?query=after%3A{bf}-12-31%20before%3A{aft}-1-1%20%EC%9D%8C%EC%A3%BC%EC%9A%B4%EC%A0%84'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(yt_url)\n",
    "    \n",
    "    # 브라우저 로드가 완료되기 위한 시간\n",
    "    time.sleep(2)\n",
    "    body = driver.find_element(By.TAG_NAME, value='body')\n",
    "\n",
    "    scroll()\n",
    "\n",
    "    # selenium을 이용해서 HTML문서를 변환한 후에는 반드시 브라우저를 종료\n",
    "    html = bs(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "\n",
    "    titleList = []\n",
    "    contentUrlList = []\n",
    "    viewcountList = []\n",
    "    commentcountList = []\n",
    "\n",
    "    for content in html.select('a#video-title'):\n",
    "        #제목 수집\n",
    "        title = content.get('title')\n",
    "\n",
    "        #URL 수집\n",
    "        content_url = 'https://www.youtube.com'+content.get('href')\n",
    "\n",
    "        #조회수 수집\n",
    "        label = content.get('aria-label')\n",
    "        split_label = label.split()\n",
    "        idx = label.split().index('조회수')\n",
    "        viewcount = split_label[idx+1]\n",
    "        viewcount=viewcount.replace(\",\",\"\")\n",
    "        viewcount=viewcount.replace(\"회\",\"\")\n",
    "\n",
    "        #빈 리스트에 추가\n",
    "        titleList.append(title)\n",
    "        contentUrlList.append(content_url)\n",
    "        viewcountList.append(int(viewcount))\n",
    "\n",
    "    yt_dic = {'영상제목' : titleList,'영상주소' : contentUrlList,'조회수' : viewcountList}\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    yt_df = pd.DataFrame(yt_dic)\n",
    "\n",
    "    #날짜 가져오기\n",
    "    dateList = []\n",
    "    for link in yt_df['영상주소']:\n",
    "        yt = YouTube(link)\n",
    "        dateList.append(yt.publish_date.date())\n",
    "\n",
    "    yt_df['날짜'] = dateList\n",
    "\n",
    "    #엑셀 파일로 저장\n",
    "    yt_df.to_excel(f'SBS_{interest}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748085be",
   "metadata": {},
   "source": [
    "### JTBC 2015~2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19ed52db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n"
     ]
    }
   ],
   "source": [
    "yr_interest = [2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "for interest in yr_interest:\n",
    "    bf = interest-1\n",
    "    aft = interest+1\n",
    "    \n",
    "    yt_url = f'https://www.youtube.com/@jtbc_news/search?query=after%3A{bf}-12-31%20before%3A{aft}-1-1%20%EC%9D%8C%EC%A3%BC%EC%9A%B4%EC%A0%84'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(yt_url)\n",
    "    \n",
    "    # 브라우저 로드가 완료되기 위한 시간\n",
    "    time.sleep(2)\n",
    "    body = driver.find_element(By.TAG_NAME, value='body')\n",
    "\n",
    "    scroll()\n",
    "\n",
    "    # selenium을 이용해서 HTML문서를 변환한 후에는 반드시 브라우저를 종료\n",
    "    html = bs(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "\n",
    "    titleList = []\n",
    "    contentUrlList = []\n",
    "    viewcountList = []\n",
    "    commentcountList = []\n",
    "\n",
    "    for content in html.select('a#video-title'):\n",
    "        #제목 수집\n",
    "        title = content.get('title')\n",
    "\n",
    "        #URL 수집\n",
    "        content_url = 'https://www.youtube.com'+content.get('href')\n",
    "\n",
    "        #조회수 수집\n",
    "        label = content.get('aria-label')\n",
    "        split_label = label.split()\n",
    "        idx = label.split().index('조회수')\n",
    "        viewcount = split_label[idx+1]\n",
    "        viewcount=viewcount.replace(\",\",\"\")\n",
    "        viewcount=viewcount.replace(\"회\",\"\")\n",
    "\n",
    "        #빈 리스트에 추가\n",
    "        titleList.append(title)\n",
    "        contentUrlList.append(content_url)\n",
    "        viewcountList.append(int(viewcount))\n",
    "\n",
    "    yt_dic = {'영상제목' : titleList,'영상주소' : contentUrlList,'조회수' : viewcountList}\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    yt_df = pd.DataFrame(yt_dic)\n",
    "\n",
    "    #날짜 가져오기\n",
    "    dateList = []\n",
    "    for link in yt_df['영상주소']:\n",
    "        yt = YouTube(link)\n",
    "        dateList.append(yt.publish_date.date())\n",
    "\n",
    "    yt_df['날짜'] = dateList\n",
    "\n",
    "    #엑셀 파일로 저장\n",
    "    yt_df.to_excel(f'JTBC_{interest}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d4882",
   "metadata": {},
   "source": [
    "### KBS 2015~2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aeffe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n",
      "스크롤 완료\n"
     ]
    }
   ],
   "source": [
    "yr_interest = [2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "for interest in yr_interest:\n",
    "    bf = interest-1\n",
    "    aft = interest+1\n",
    "    \n",
    "    yt_url = f'https://www.youtube.com/@newskbs/search?query=after%3A{bf}-12-31%20before%3A{aft}-1-1%20%EC%9D%8C%EC%A3%BC%EC%9A%B4%EC%A0%84'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(yt_url)\n",
    "    \n",
    "    # 브라우저 로드가 완료되기 위한 시간\n",
    "    time.sleep(2)\n",
    "    body = driver.find_element(By.TAG_NAME, value='body')\n",
    "\n",
    "    scroll()\n",
    "\n",
    "    # selenium을 이용해서 HTML문서를 변환한 후에는 반드시 브라우저를 종료\n",
    "    html = bs(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "\n",
    "    titleList = []\n",
    "    contentUrlList = []\n",
    "    viewcountList = []\n",
    "    commentcountList = []\n",
    "\n",
    "    for content in html.select('a#video-title'):\n",
    "        #제목 수집\n",
    "        title = content.get('title')\n",
    "\n",
    "        #URL 수집\n",
    "        content_url = 'https://www.youtube.com'+content.get('href')\n",
    "\n",
    "        #조회수 수집\n",
    "        label = content.get('aria-label')\n",
    "        split_label = label.split()\n",
    "        idx = label.split().index('조회수')\n",
    "        viewcount = split_label[idx+1]\n",
    "        viewcount=viewcount.replace(\",\",\"\")\n",
    "        viewcount=viewcount.replace(\"회\",\"\")\n",
    "\n",
    "        #빈 리스트에 추가\n",
    "        titleList.append(title)\n",
    "        contentUrlList.append(content_url)\n",
    "        viewcountList.append(int(viewcount))\n",
    "\n",
    "    yt_dic = {'영상제목' : titleList,'영상주소' : contentUrlList,'조회수' : viewcountList}\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    yt_df = pd.DataFrame(yt_dic)\n",
    "\n",
    "    #날짜 가져오기\n",
    "    dateList = []\n",
    "    for link in yt_df['영상주소']:\n",
    "        yt = YouTube(link)\n",
    "        dateList.append(yt.publish_date.date())\n",
    "\n",
    "    yt_df['날짜'] = dateList\n",
    "\n",
    "    #엑셀 파일로 저장\n",
    "    yt_df.to_excel(f'KBS_{interest}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250123a8",
   "metadata": {},
   "source": [
    "## [2] 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.stats import probplot\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3864325",
   "metadata": {},
   "source": [
    "### JTBC, KBS, MBC, SBS, YTN의 음주운전 관련 영상 (2015~2022) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JTBC={}\n",
    "df_KBS={}\n",
    "df_MBC={}\n",
    "df_SBS={}\n",
    "df_YTN={}\n",
    "df=[df_JTBC,df_KBS,df_MBC,df_SBS,df_YTN]\n",
    "\n",
    "compList = ['JTBC','KBS','MBC','SBS','YTN']\n",
    "yearList = [2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "\n",
    "\n",
    "for year in yearList:\n",
    "    for i,comp in enumerate(compList):\n",
    "        df_data = df[i]\n",
    "        dataset_path = f\"/Users/yewonsong/Desktop/EDA/{comp}/\"\n",
    "        file_path = os.path.join(dataset_path,f\"{comp}_{year}.xlsx\")\n",
    "        df_data[year]=pd.read_excel(file_path)\n",
    "        \n",
    "        df_data[year].drop('Unnamed: 0',axis=1,inplace=True) #필요없는 컬럼 제거 \n",
    "        df_data[year] = df_data[year].drop_duplicates() #중복 행 제거\n",
    "        df_data[year] = df_data[year].sort_values(by='날짜') #날짜 순으로 재정렬\n",
    "        df_data[year]['month']=df_data[year]['날짜'].dt.strftime('%Y-%m') #month 컬럼 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780e132",
   "metadata": {},
   "source": [
    "### 회사 별로 모든 년도 합치기 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JTBC_all = df_JTBC[2015]\n",
    "for year in yearList[1:]:\n",
    "    df_JTBC_all = pd.concat([df_JTBC_all, df_JTBC[year]],axis=0).reset_index(drop=True)\n",
    "    df_JTBC_all = df_JTBC_all.drop_duplicates()\n",
    "    df_JTBC_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_KBS_all = df_KBS[2015]\n",
    "for year in yearList[1:]:\n",
    "    df_KBS_all = pd.concat([df_KBS_all, df_KBS[year]],axis=0).reset_index(drop=True)\n",
    "    df_KBS_all = df_KBS_all.drop_duplicates()\n",
    "    df_KBS_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_MBC_all = df_MBC[2015]\n",
    "for year in yearList[1:]:\n",
    "    df_MBC_all = pd.concat([df_MBC_all, df_MBC[year]],axis=0).reset_index(drop=True)\n",
    "    df_MBC_all = df_MBC_all.drop_duplicates()\n",
    "    df_MBC_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_SBS_all = df_SBS[2015]\n",
    "for year in yearList[1:]:\n",
    "    df_SBS_all = pd.concat([df_SBS_all, df_SBS[year]],axis=0).reset_index(drop=True)\n",
    "    df_SBS_all = df_SBS_all.drop_duplicates()\n",
    "    df_SBS_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_YTN_all = df_YTN[2015]\n",
    "for year in yearList[1:]:\n",
    "    df_YTN_all = pd.concat([df_YTN_all, df_YTN[year]],axis=0).reset_index(drop=True)\n",
    "    df_YTN_all = df_YTN_all.drop_duplicates()\n",
    "    df_YTN_all.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b914e5d",
   "metadata": {},
   "source": [
    "### 음주 관련 영상들만 남겨주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop=[]\n",
    "keyword=['음주운전','음주뺑소니','윤창호','음주차량','음주사고','만취운전','음주단속']\n",
    "\n",
    "#JTBC\n",
    "for i, title in enumerate(df_JTBC_all['영상제목']):\n",
    "    count = 0\n",
    "    title_test = re.sub('[^A-Za-z가-힣]','',title)\n",
    "    for key in keyword:\n",
    "        if key in title_test:\n",
    "            count =+ 1\n",
    "    if count == 0:\n",
    "        todrop.append(i)\n",
    "        \n",
    "df_JTBC_all.drop(todrop,axis=0,inplace=True)\n",
    "df_JTBC_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#KBS\n",
    "for i, title in enumerate(df_KBS_all['영상제목']):\n",
    "    count = 0\n",
    "    title_test = re.sub('[^A-Za-z가-힣]','',title)\n",
    "    for key in keyword:\n",
    "        if key in title_test:\n",
    "            count =+ 1\n",
    "    if count == 0:\n",
    "        todrop.append(i)\n",
    "\n",
    "df_KBS_all.drop(todrop,axis=0,inplace=True)\n",
    "df_KBS_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#MBC\n",
    "for i, title in enumerate(df_MBC_all['영상제목']):\n",
    "    count = 0\n",
    "    title_test = re.sub('[^A-Za-z가-힣]','',title)\n",
    "    for key in keyword:\n",
    "        if key in title_test:\n",
    "            count =+ 1\n",
    "    if count == 0:\n",
    "        todrop.append(i)\n",
    "\n",
    "df_MBC_all.drop(todrop,axis=0,inplace=True)\n",
    "df_MBC_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#SBS\n",
    "for i, title in enumerate(df_SBS_all['영상제목']):\n",
    "    count = 0\n",
    "    title_test = re.sub('[^A-Za-z가-힣]','',title)\n",
    "    for key in keyword:\n",
    "        if key in title_test:\n",
    "            count =+ 1\n",
    "    if count == 0:\n",
    "        todrop.append(i)\n",
    "\n",
    "df_SBS_all.drop(todrop,axis=0,inplace=True)\n",
    "df_SBS_all.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#YTN\n",
    "for i, title in enumerate(df_YTN_all['영상제목']):\n",
    "    count = 0\n",
    "    title_test = re.sub('[^A-Za-z가-힣]','',title)\n",
    "    for key in keyword:\n",
    "        if key in title_test:\n",
    "            count =+ 1\n",
    "    if count == 0:\n",
    "        todrop.append(i)\n",
    "\n",
    "df_YTN_all.drop(todrop,axis=0,inplace=True)\n",
    "df_YTN_all.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e3394a",
   "metadata": {},
   "source": [
    "### 월별 조회수 데이터 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JTBC_views = df_JTBC_all.groupby('month').sum('조회수')\n",
    "df_KBS_views = df_KBS_all.groupby('month').sum('조회수')\n",
    "df_MBC_views = df_MBC_all.groupby('month').sum('조회수')\n",
    "df_SBS_views = df_SBS_all.groupby('month').sum('조회수')\n",
    "df_YTN_views = df_YTN_all.groupby('month').sum('조회수')\n",
    "\n",
    "#월별 영상수, 평균조회수 컬럼 생성\n",
    "JTBC_count = df_JTBC_all.groupby('month').size().to_frame()\n",
    "df_JTBC = pd.merge(df_JTBC_views,JTBC_count,left_index=True,right_index=True)\n",
    "df_JTBC.columns = ['view','count']\n",
    "df_JTBC['avg'] = df_JTBC['view']/df_JTBC['count']\n",
    "df_JTBC.columns = ['view','count','avg_view']\n",
    "\n",
    "KBS_count = df_KBS_all.groupby('month').size().to_frame()\n",
    "df_KBS = pd.merge(df_KBS_views,KBS_count,left_index=True,right_index=True)\n",
    "df_KBS.columns = ['view','count']\n",
    "df_KBS['avg'] = df_KBS['view']/df_KBS['count']\n",
    "df_KBS.columns = ['view','count','avg_view']\n",
    "\n",
    "MBC_count = df_MBC_all.groupby('month').size().to_frame()\n",
    "df_MBC = pd.merge(df_MBC_views,MBC_count,left_index=True,right_index=True)\n",
    "df_MBC.columns = ['view','count']\n",
    "df_MBC['avg'] = df_MBC['view']/df_MBC['count']\n",
    "df_MBC.columns = ['view','count','avg_view']\n",
    "\n",
    "SBS_count = df_SBS_all.groupby('month').size().to_frame()\n",
    "df_SBS = pd.merge(df_SBS_views,SBS_count,left_index=True,right_index=True)\n",
    "df_SBS.columns = ['view','count']\n",
    "df_SBS['avg'] = df_SBS['view']/df_SBS['count']\n",
    "df_SBS.columns = ['view','count','avg_view']\n",
    "\n",
    "YTN_count = df_YTN_all.groupby('month').size().to_frame()\n",
    "df_YTN = pd.merge(df_YTN_views,YTN_count,left_index=True,right_index=True)\n",
    "df_YTN.columns = ['view','count']\n",
    "df_YTN['avg'] = df_YTN['view']/df_YTN['count']\n",
    "df_YTN.columns = ['view','count','avg_view']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb40f5",
   "metadata": {},
   "source": [
    "### 5개 회사 합치기 df_YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5개 회사 합치기\n",
    "merged = pd.merge(df_JTBC,df_KBS,how='outer',left_on='month',right_on='month').sort_values('month')\n",
    "merged = pd.merge(merged,df_MBC,how='outer',left_on='month',right_on='month').sort_values('month')\n",
    "merged = pd.merge(merged,df_SBS,how='outer',left_on='month',right_on='month').sort_values('month')\n",
    "merged = pd.merge(merged,df_YTN,how='outer',left_on='month',right_on='month').sort_values('month')\n",
    "\n",
    "#컬럼 이름 재 설정 \n",
    "merged.columns = ['JTBC_view','JTBC_count','JTBC_avg',\n",
    "                  'KBS_view','KBS_count','KBS_avg',\n",
    "                  'MBC_view','MBC_count','MBC_avg',\n",
    "                  'SBS_view','SBS_count','SBS_avg',\n",
    "                  'YTN_view','YTN_count','YTN_avg']\n",
    "\n",
    "#NA 값 0으로 바꾸기 \n",
    "merged = merged.fillna(0)\n",
    "merged\n",
    "\n",
    "#sum 컬럼 만들기\n",
    "merged['sum_view']=merged['JTBC_view']+merged['KBS_view']+merged['MBC_view']+merged['SBS_view']+merged['YTN_view'] \n",
    "merged['sum_count']=merged['JTBC_count']+merged['KBS_count']+merged['MBC_count']+merged['SBS_count']+merged['YTN_count']\n",
    "merged['avg_view']=merged['sum_view']/merged['sum_count']\n",
    "\n",
    "#이름 바꾸기\n",
    "df_yt = merged\n",
    "df_yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c89e0",
   "metadata": {},
   "source": [
    "### 월별 교통사고 건수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#월별 사고 건수\n",
    "dataset_path = \"/Users/yewonsong/Desktop/EDA/data/일자별\"\n",
    "df_accident = {} #사고 (건)\n",
    "df_fatal = {} #사망 (명)\n",
    "df_injury = {} #부상 (명)\n",
    "df_dataset = [df_accident, df_fatal, df_injury]\n",
    "\n",
    "for year in range(2005,2023):\n",
    "    for i in range(3):\n",
    "        df_data=df_dataset[i] #df_accident, df_fatal, df_injury 각각 만들어주기\n",
    "        file_path=os.path.join(dataset_path,f\"일자별 음주운전사고 {year}.xls\")\n",
    "        if os.path.exists(file_path):\n",
    "            try: \n",
    "                df_data[year]=pd.read_excel(file_path,header=1) #열 이름으로 사용할 행 지정\n",
    "                \n",
    "                row_to_drop=[j for j in range(40) if j%3!=i] #drop할 행 번호\n",
    "                row_to_drop.append(i) #합계도 지워주기\n",
    "                df_data[year].drop(row_to_drop,inplace=True,axis=0) #행 제거\n",
    "                df_data[year].set_index(df_data[year].columns[0], inplace=True)\n",
    "                \n",
    "                col_to_drop=['사고년도','합계']\n",
    "                df_data[year].drop(col_to_drop,inplace=True,axis=1)\n",
    "                \n",
    "                if df_data[year].index.isna().any().any(): #행에 하나라도 na가 있으면 \n",
    "                    df_data[year].drop(np.nan,inplace=True,axis=0) #그 행 삭제...\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file for {i} year {year}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found for year: {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "for year in range(2005,2023):\n",
    "    df_accident[year] = df_accident[year].replace('-',0)\n",
    "    df_accident[year].astype(int)\n",
    "    df_accident[year]['sum_acc']=df_accident[year].loc[:,:].sum(axis=1) #월별 사고 건수 합 컬럼 생성\n",
    "    \n",
    "    #날짜 열 생성\n",
    "    start_date=f'{year}0101'\n",
    "    end_date=f'{year}1231'\n",
    "    date_list=pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "    dateList = []\n",
    "    for date in date_list:\n",
    "        date = date.strftime('%Y-%m')\n",
    "        dateList.append(date)\n",
    "    df_accident[year]['date']= dateList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f684a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 월 합쳐주기\n",
    "df_acc = df_accident[2015]\n",
    "for year in range(2016,2023):\n",
    "    df_acc = pd.concat([df_acc,df_accident[year]],axis=0)\n",
    "df_acc.set_index('date',drop=True,inplace=True)\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea52b4f",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb010fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사고 추세 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "dates = pd.date_range(start='2015-01-01', periods=len(df_acc), freq='M')\n",
    "plt.plot(dates,df_acc['sum_acc'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.title('Number of accidents by month (2015.01-2022.12)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#조회수 추세 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "dates = pd.date_range(start='2015-01-01', periods=len(df_yt), freq='M')\n",
    "plt.plot(dates, df_yt['sum_view'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Views')\n",
    "plt.title('Youtube Views by month (2015.01-2022.12)')\n",
    "#start = df_yt.index[0]\n",
    "#end = df_yt.index[-1]\n",
    "#plt.xlim(start,end)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#영상 수 추세 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(dates, df_yt['sum_count'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Videos')\n",
    "plt.title('Number of Youtube Videos by month (2015.01-2022.12)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc72994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균 조회수 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(dates, df_yt['avg_view'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average views')\n",
    "plt.title('Average Youtube Views by month (2015.01-2022.12)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c349432",
   "metadata": {},
   "source": [
    "### df_yt_acc: 조회수, 영상 수, 평균조회수, 사고 건수 합친 data frame 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9df7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = df_yt.loc[:,['sum_view','sum_count','avg_view']]\n",
    "acc = df_acc['sum_acc'].to_frame()\n",
    "df_yt_acc = pd.merge(acc,yt,left_index=True,right_index=True)\n",
    "df_yt_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ac9a7",
   "metadata": {},
   "source": [
    "### 이상치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack features and targets for joint outlier removal\n",
    "data = np.column_stack((df_yt_acc['sum_acc'],df_yt_acc['sum_view']))\n",
    "print(data.shape)\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = np.percentile(data, 25, axis=0)\n",
    "Q3 = np.percentile(data, 75, axis=0)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outliers\n",
    "outlier_mask = np.any((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR)), axis=1)\n",
    "\n",
    "# Filter out the outliers\n",
    "data_no_outliers = data[~outlier_mask]\n",
    "print(data_no_outliers.shape)\n",
    "\n",
    "# Separate features and targets again\n",
    "acc_no_outliers = data_no_outliers[:, 0]\n",
    "views_no_outliers = data_no_outliers[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbbafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(views_no_outliers) #right skewed => log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(views_no_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF no outliers\n",
    "log_view_no_outliers = np.log(views_no_outliers)\n",
    "df_no_outliers = {'log_view': log_view_no_outliers.flatten().tolist(),\n",
    "        'acc': acc_no_outliers.flatten().tolist()}\n",
    "df_no_outliers = pd.DataFrame(df_no_outliers)\n",
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_log_view_no = scaler.fit_transform(np.array(df_no_outliers['log_view']).reshape(-1, 1))\n",
    "scaled_acc_no = scaler.fit_transform(np.array(df_no_outliers['acc']).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cf812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF Scaled no outliers\n",
    "df_scaled_no_outliers = {'log_view': scaled_log_view_no.flatten().tolist(),\n",
    "        'acc': scaled_acc_no.flatten().tolist()}\n",
    "df_scaled_no_outliers = pd.DataFrame(df_scaled_no_outliers)\n",
    "df_scaled_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb43d2c",
   "metadata": {},
   "source": [
    "### 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_outliers= LinearRegression().fit(scaled_log_view_no, scaled_acc_no)\n",
    "coef = model_no_outliers.coef_[0]\n",
    "intercept = model_no_outliers.intercept_\n",
    "r_squared = model_no_outliers.score(scaled_log_view_no, scaled_acc_no)\n",
    "print(f\"Coefficient: {coef}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "print(f\"R-squared: {r_squared}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관분석\n",
    "X = df_scaled_no_outliers['log_view'].values\n",
    "Y = df_scaled_no_outliers['acc'].values\n",
    "stats.pearsonr(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_no_outliers.predict(np.array([0.0, 1.0]).reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.title(\"Number of Accident by Youtube Views \\nby month (2015.01-2022.12)\")\n",
    "plt.xlabel(\"MinMax-Scaled log(Youtube Views)\")\n",
    "plt.ylabel(\"MinMax-Scaled Number of Accident\")\n",
    "plt.scatter(scaled_log_view_no, scaled_acc_no, color='blue',s=10)\n",
    "plt.plot(scaled_log_view_no,fit.fittedvalues, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d788b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#회귀계수의 유의성 검정 (t-statistic, p-value)\n",
    "x = scaled_log_view_no\n",
    "y = scaled_acc_no\n",
    "n = len(x)\n",
    "p = 1  \n",
    "\n",
    "#t-statistic\n",
    "mse = np.mean((model_no_outliers.predict(x) - y) ** 2)\n",
    "se = np.sqrt(mse / (n - p - 1) / np.sum((x - np.mean(x)) ** 2))\n",
    "t_stat = coef / se\n",
    "\n",
    "#p-value\n",
    "p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), n - p - 1))\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "#Check if the coefficient is significant\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The coefficient is statistically significant.\")\n",
    "else:\n",
    "    print(\"The coefficient is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d677844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형 모형 적합\n",
    "fit = ols('scaled_acc_no ~ scaled_log_view_no', data=df_scaled_no_outliers).fit()\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ee9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규성 검정\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "sm.qqplot(fit.resid, fit = True, line = \"45\", color='grey')\n",
    "plt.show()\n",
    "\n",
    "#Shapiro-wilk test \n",
    "stats.shapiro(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#등분산성 검정\n",
    "y_pred = model_no_outliers.predict(x)\n",
    "residuals = y - y_pred\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_pred, residuals, color='blue', s=10)\n",
    "plt.hlines(y=0, xmin=min(y_pred), xmax=max(y_pred), colors='red', linestyles='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
