{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYSLTUK_amcX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import itertools\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import csv\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    r2_score,\n",
        "    mean_squared_error,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8kJuIn2amca"
      },
      "outputs": [],
      "source": [
        "path = \"/Users/jrock/Documents/Yonsei/DSL/EDA/cp/onehotencode.csv\"\n",
        "data = pd.read_csv(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E72ZoxOamcd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = data.drop(['#종속변수'], axis = 1)\n",
        "y = data['#종속변수']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mRMR"
      ],
      "metadata": {
        "id": "srMCaf5xhORM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 15\n",
        "S = []\n",
        "\n",
        "\n",
        "# Calculate the Spearman correlation matrix\n",
        "corr_matrix = data.corr(method='spearman')\n",
        "\n",
        "# Remove the target variable from the correlation matrix\n",
        "corr_matrix = corr_matrix.drop('Annual Revenue LTM (USD)', axis=0)\n",
        "\n",
        "# Find the feature with the highest relevance (minimum redundancy)\n",
        "highest_corr_idx = np.argmin(np.abs(corr_matrix['Annual Revenue LTM (USD)']))\n",
        "first_feature = corr_matrix.index[highest_corr_idx]\n",
        "\n",
        "S.append(first_feature)\n",
        "\n",
        "for i in range(k - 1):\n",
        "    relevance = np.abs(corr_matrix['Annual Revenue LTM (USD)'])\n",
        "    redundancy = np.mean(np.abs(corr_matrix.loc[:, S]), axis=1)\n",
        "    candidate_feature = relevance - redundancy\n",
        "    candidate_feature = candidate_feature.drop(S)\n",
        "    best_x_idx = np.argmax(candidate_feature)\n",
        "    next_feature = candidate_feature.index[best_x_idx]\n",
        "    S.append(next_feature)"
      ],
      "metadata": {
        "id": "oMkt2gbJhM0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S"
      ],
      "metadata": {
        "id": "9XsmJsXrhQnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrmr_features = S.copy()"
      ],
      "metadata": {
        "id": "VytCKjvThS86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrmr_X_train = X_train[mrmr_features]\n",
        "mrmr_X_test = X_test[mrmr_features]"
      ],
      "metadata": {
        "id": "-0Eg91yWhT7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create a RandomForestRegressor\n",
        "rf_regressor = RandomForestRegressor(random_state=486)\n",
        "\n",
        "# Train the regressor\n",
        "rf_regressor.fit(mrmr_X_train, y_train)\n",
        "\n",
        "# Assuming mrmr_X_test is your feature matrix for testing\n",
        "# Use the trained model to make predictions on new data\n",
        "y_pred = rf_regressor.predict(mrmr_X_test)\n",
        "\n",
        "# Evaluate the performance of the model (you may use other metrics depending on your problem)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "rf = RandomForestRegressor(random_state=486)\n",
        "rf.fit(mrmr_X_train, y_train)"
      ],
      "metadata": {
        "id": "4pkFxTBQhVHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Use the trained model to make predictions on new data\n",
        "test_pred = rf_regressor.predict(mrmr_X_test)\n",
        "\n",
        "# Evaluate the performance of the regression model\n",
        "mae = mean_absolute_error(y_test, test_pred)\n",
        "mse = mean_squared_error(y_test, test_pred)\n",
        "r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "print('[mRMR 변수 선택]')\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared (R2):\", r2)"
      ],
      "metadata": {
        "id": "57AMOeX3hW4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "변수 중요도 출력"
      ],
      "metadata": {
        "id": "7_dHMagFhZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = rf_regressor.feature_importances_\n",
        "\n",
        "feature_names = mrmr_X_train.columns\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print or display the sorted feature importances\n",
        "print('[mRMR 변수 선택]')\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "id": "wPhOfofuhYzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "24fda0f7bd1a36ebd248fab6250e510265f6475b7b3a6dc37c5bb872779c21cf"
    },
    "kernelspec": {
      "display_name": "Python 3.10.9 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}